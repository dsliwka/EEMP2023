{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Course Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "209.391px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "WS1920_EEMP_exam_PT1_solutions.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsliwka/EEMP2022/blob/main/notebooks/WS1920_EEMP_exam_PT1_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AoqY_ZrnIF0"
      },
      "source": [
        "# *- Solutions -*\n",
        "\n",
        "# 1253BMEE00 FA MP MB Econometric Evaluation of Management Practices\n",
        "## Examiner: Prof. Dr. Dirk Sliwka\n",
        "## Date: 02.12.2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXWI5ZpLnIF0"
      },
      "source": [
        "## Instructions:\n",
        "\n",
        "Please follow the instructions below, such that we will be able to correctly identify your solutions to the exam.\n",
        "\n",
        "**1. Please take a copy of this jupyter notebook and save it as a separate file in the following format:**\n",
        "\n",
        "*WS1920_EEMP_exam_PT1_matriculationnumber_initials.ipynb*\n",
        "\n",
        "- i.e., the final file name should look like this: *WS1920_EEMP_exam_PT1_1234567_MM.ipynb*\n",
        "\n",
        "**2. Please also enter your matriculation number and your initials in the following cell:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqsfGJGAnIF0"
      },
      "source": [
        "### Matriculation number:\n",
        "### Initials:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2mETUM2nIF0"
      },
      "source": [
        "## Background information\n",
        "\n",
        "The datasets provided on the memory sticks contain data from a study by Bloom et al. (2015): *Does Working from Home Work? Evidence from a Chinese Experiment*, where the authors evaluate the performance effect of giving Chinese call-center employees the opportunity to work from home. To do this, they first asked the employees whether they would generally be willing to work from home. Of those employees who volunteered to work from home, they **<u>randomly</u>** chose a **subgroup** which was actually given the **opportunity to work from home** (**treatment group**). Those employees who **volunteered**, but were **not given the opportunity to work from home**, serve as the **control group**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbPDAz29nIF0"
      },
      "source": [
        "The code cell below imports the standard module *pandas*. It also imports the two datasets relevant for this exam, provided that the specified paths are correct (this depends on where you saved the files on your laptop). Please execute this cell before you start your work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LytHLNK3nIF0"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "path_data_task1 = 'https://raw.githubusercontent.com/armoutihansen/EEMP2020/main/datasets/data_task1.csv'\n",
        "df1 = pd.read_csv(path_data_task1)\n",
        "\n",
        "path_data_task2 = 'https://raw.githubusercontent.com/dsliwka/EEMP2022/main/datasets/data_performance.csv'\n",
        "df2 = pd.read_csv(path_data_task2)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UmuBq9FnIF0"
      },
      "source": [
        "# further imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import seaborn as sns\n",
        "from statsmodels.iolib.summary2 import summary_col\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q46hK_JGnIF1"
      },
      "source": [
        "*Good luck!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqJZZ9nGnIF1"
      },
      "source": [
        "## Assignment 1 (30 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg5j_ieEnIF1"
      },
      "source": [
        "The dataset *data_task1.csv* contains the following variables from the experimental period (that is the time frame in which the treatment group worked from home):\n",
        "- *personid*: individual employee identifier\n",
        "- *calllength*: performance measure, indicating the weekly sum of minutes on the phone\n",
        "- *treatment*: treatment dummy, indicating whether the employee was part of the treatment group\n",
        "- *commute120*: commuting dummy, indicating whether the employee has to commute more than 120 minutes in total\n",
        "- *year_week*: indicator for year and calender week\n",
        "\n",
        "__a)__ Using *data_task1.csv*, estimate the following OLS regression and show its output using python (remember to cluster the standard errors on the \"personid\" level):\n",
        "\n",
        "**Regression 1**: $$ ln(calllength) = \\alpha + \\beta_{1} * treatment + \\beta_{t} * year\\_week_{t} + \\epsilon $$\n",
        "\n",
        "*Note:* To account for seasonal variation beta_t reflects the full set of weekly time dummies.\n",
        "\n",
        "\n",
        "Please give a precise verbal interpretation of the coefficient for treatment and its statistical significance.   \n",
        "\n",
        "\n",
        "\n",
        "<div style=\"text-align: right\"> <b>10 points</b> </div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkynje40nIF1",
        "outputId": "87deb457-def3-4b69-9d4a-f17e2e1db887"
      },
      "source": [
        "# Insert your code here:\n",
        "\n",
        "# generate log variable\n",
        "df1['logcalllength']=np.log(df1['calllength'])\n",
        "\n",
        "# regression 1\n",
        "\n",
        "reg1=smf.ols('logcalllength ~ treatment + C(year_week)', data=df1).fit(cov_type='cluster',cov_kwds={'groups':df1['personid']})\n",
        "print(reg1.summary())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          logcalllength   R-squared:                       0.073\n",
            "Model:                            OLS   Adj. R-squared:                  0.064\n",
            "Method:                 Least Squares   F-statistic:                     8.738\n",
            "Date:                Mon, 21 Nov 2022   Prob (F-statistic):           4.83e-21\n",
            "Time:                        17:13:48   Log-Likelihood:                -1660.7\n",
            "No. Observations:                3719   AIC:                             3397.\n",
            "Df Residuals:                    3681   BIC:                             3634.\n",
            "Df Model:                          37                                         \n",
            "Covariance Type:              cluster                                         \n",
            "==========================================================================================\n",
            "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------\n",
            "Intercept                 11.0568      0.038    289.384      0.000      10.982      11.132\n",
            "C(year_week)[T.201051]     0.0703      0.031      2.250      0.024       0.009       0.131\n",
            "C(year_week)[T.201052]    -0.0253      0.044     -0.576      0.565      -0.111       0.061\n",
            "C(year_week)[T.201053]    -0.0615      0.039     -1.591      0.112      -0.137       0.014\n",
            "C(year_week)[T.201101]    -0.0900      0.041     -2.191      0.028      -0.171      -0.009\n",
            "C(year_week)[T.201102]     0.1777      0.037      4.765      0.000       0.105       0.251\n",
            "C(year_week)[T.201103]     0.0940      0.044      2.134      0.033       0.008       0.180\n",
            "C(year_week)[T.201104]    -0.0547      0.043     -1.257      0.209      -0.140       0.031\n",
            "C(year_week)[T.201105]    -0.1592      0.055     -2.875      0.004      -0.268      -0.051\n",
            "C(year_week)[T.201106]    -0.0342      0.057     -0.602      0.547      -0.146       0.077\n",
            "C(year_week)[T.201107]    -0.0556      0.050     -1.104      0.270      -0.154       0.043\n",
            "C(year_week)[T.201108]    -0.0068      0.046     -0.148      0.882      -0.097       0.083\n",
            "C(year_week)[T.201109]     0.0189      0.047      0.398      0.690      -0.074       0.112\n",
            "C(year_week)[T.201110]     0.0358      0.049      0.729      0.466      -0.061       0.132\n",
            "C(year_week)[T.201111]     0.0652      0.039      1.677      0.093      -0.011       0.141\n",
            "C(year_week)[T.201112]     0.0786      0.043      1.844      0.065      -0.005       0.162\n",
            "C(year_week)[T.201113]     0.1085      0.045      2.438      0.015       0.021       0.196\n",
            "C(year_week)[T.201114]    -0.0248      0.054     -0.463      0.644      -0.130       0.080\n",
            "C(year_week)[T.201115]     0.1402      0.054      2.581      0.010       0.034       0.247\n",
            "C(year_week)[T.201116]     0.1336      0.064      2.087      0.037       0.008       0.259\n",
            "C(year_week)[T.201117]     0.2589      0.044      5.845      0.000       0.172       0.346\n",
            "C(year_week)[T.201118]     0.0307      0.044      0.704      0.481      -0.055       0.116\n",
            "C(year_week)[T.201119]     0.0578      0.045      1.283      0.199      -0.030       0.146\n",
            "C(year_week)[T.201120]     0.1342      0.047      2.874      0.004       0.043       0.226\n",
            "C(year_week)[T.201121]     0.0595      0.047      1.265      0.206      -0.033       0.152\n",
            "C(year_week)[T.201122]     0.0794      0.041      1.915      0.055      -0.002       0.161\n",
            "C(year_week)[T.201123]     0.0381      0.038      0.992      0.321      -0.037       0.113\n",
            "C(year_week)[T.201124]     0.0834      0.042      1.963      0.050       0.000       0.167\n",
            "C(year_week)[T.201125]     0.0303      0.042      0.724      0.469      -0.052       0.112\n",
            "C(year_week)[T.201126]     0.1014      0.044      2.297      0.022       0.015       0.188\n",
            "C(year_week)[T.201127]     0.1542      0.048      3.211      0.001       0.060       0.248\n",
            "C(year_week)[T.201128]     0.2038      0.048      4.220      0.000       0.109       0.299\n",
            "C(year_week)[T.201129]     0.2140      0.042      5.057      0.000       0.131       0.297\n",
            "C(year_week)[T.201130]     0.2128      0.042      5.031      0.000       0.130       0.296\n",
            "C(year_week)[T.201131]     0.2389      0.042      5.627      0.000       0.156       0.322\n",
            "C(year_week)[T.201132]     0.2161      0.044      4.957      0.000       0.131       0.302\n",
            "C(year_week)[T.201133]     0.1990      0.044      4.570      0.000       0.114       0.284\n",
            "treatment                  0.0721      0.038      1.895      0.058      -0.002       0.147\n",
            "==============================================================================\n",
            "Omnibus:                     1643.701   Durbin-Watson:                   2.056\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            11056.193\n",
            "Skew:                          -1.984   Prob(JB):                         0.00\n",
            "Kurtosis:                      10.457   Cond. No.                         41.2\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors are robust to cluster correlation (cluster)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6mTc8jqnIF2"
      },
      "source": [
        "'# Give the verbal answer here:\n",
        "\n",
        "- the coefficient of the treatment dummy amounts to 0.0721 and is statistically significant at the 10% level (p=0.058). The size of the coefficient can be interpreted as follows: employees in the treatment group, i.e. that are working from home, show a performance, i.e. average weekly sum of minutes on the phone, that is 7,21% higher compared to workers that do not work from home."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q1xBoLxnIF2"
      },
      "source": [
        "__b)__ In a next step, please explore in another regression (Regression 2) whether the size of the treatment effect depends on the commuting distance (remember to cluster the standard errors on the \"personid\" level and as before include the full set of weekly time dummies).\n",
        "\n",
        "\n",
        "Please give a precise verbal interpretation of the results and the respective magnitudes of your estimates. Explain what this means for the effectiveness of the working from home treatment intervention and elaborate on potential reasons. \n",
        "\n",
        "\n",
        "\n",
        "<div style=\"text-align: right\"> <b>10 points</b> </div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9HjbSjAnIF2",
        "outputId": "f55a7fda-c306-4d9a-a5be-1b250285c9d3"
      },
      "source": [
        "# Insert your code here:\n",
        "\n",
        "# regression 2\n",
        "reg2=smf.ols('logcalllength ~ treatment*commute120 + C(year_week)', data=df1).fit(cov_type='cluster',cov_kwds={'groups':df1['personid']})\n",
        "print(reg2.summary())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          logcalllength   R-squared:                       0.081\n",
            "Model:                            OLS   Adj. R-squared:                  0.071\n",
            "Method:                 Least Squares   F-statistic:                     8.719\n",
            "Date:                Mon, 21 Nov 2022   Prob (F-statistic):           1.90e-21\n",
            "Time:                        17:13:49   Log-Likelihood:                -1645.2\n",
            "No. Observations:                3719   AIC:                             3370.\n",
            "Df Residuals:                    3679   BIC:                             3619.\n",
            "Df Model:                          39                                         \n",
            "Covariance Type:              cluster                                         \n",
            "==========================================================================================\n",
            "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------\n",
            "Intercept                 11.0403      0.048    230.799      0.000      10.947      11.134\n",
            "C(year_week)[T.201051]     0.0699      0.031      2.230      0.026       0.008       0.131\n",
            "C(year_week)[T.201052]    -0.0248      0.044     -0.566      0.571      -0.111       0.061\n",
            "C(year_week)[T.201053]    -0.0627      0.039     -1.625      0.104      -0.138       0.013\n",
            "C(year_week)[T.201101]    -0.0906      0.041     -2.208      0.027      -0.171      -0.010\n",
            "C(year_week)[T.201102]     0.1773      0.037      4.734      0.000       0.104       0.251\n",
            "C(year_week)[T.201103]     0.0939      0.044      2.131      0.033       0.008       0.180\n",
            "C(year_week)[T.201104]    -0.0531      0.043     -1.223      0.221      -0.138       0.032\n",
            "C(year_week)[T.201105]    -0.1597      0.055     -2.887      0.004      -0.268      -0.051\n",
            "C(year_week)[T.201106]    -0.0358      0.057     -0.631      0.528      -0.147       0.075\n",
            "C(year_week)[T.201107]    -0.0558      0.050     -1.111      0.266      -0.154       0.043\n",
            "C(year_week)[T.201108]    -0.0052      0.046     -0.113      0.910      -0.095       0.085\n",
            "C(year_week)[T.201109]     0.0196      0.047      0.414      0.679      -0.073       0.112\n",
            "C(year_week)[T.201110]     0.0365      0.049      0.744      0.457      -0.060       0.133\n",
            "C(year_week)[T.201111]     0.0659      0.039      1.703      0.088      -0.010       0.142\n",
            "C(year_week)[T.201112]     0.0778      0.043      1.831      0.067      -0.005       0.161\n",
            "C(year_week)[T.201113]     0.1087      0.045      2.439      0.015       0.021       0.196\n",
            "C(year_week)[T.201114]    -0.0229      0.053     -0.428      0.669      -0.128       0.082\n",
            "C(year_week)[T.201115]     0.1413      0.054      2.604      0.009       0.035       0.248\n",
            "C(year_week)[T.201116]     0.1346      0.064      2.104      0.035       0.009       0.260\n",
            "C(year_week)[T.201117]     0.2578      0.044      5.833      0.000       0.171       0.344\n",
            "C(year_week)[T.201118]     0.0302      0.043      0.696      0.487      -0.055       0.115\n",
            "C(year_week)[T.201119]     0.0588      0.045      1.309      0.190      -0.029       0.147\n",
            "C(year_week)[T.201120]     0.1337      0.047      2.870      0.004       0.042       0.225\n",
            "C(year_week)[T.201121]     0.0593      0.047      1.264      0.206      -0.033       0.151\n",
            "C(year_week)[T.201122]     0.0793      0.041      1.919      0.055      -0.002       0.160\n",
            "C(year_week)[T.201123]     0.0379      0.038      0.991      0.322      -0.037       0.113\n",
            "C(year_week)[T.201124]     0.0830      0.043      1.952      0.051      -0.000       0.166\n",
            "C(year_week)[T.201125]     0.0297      0.042      0.713      0.476      -0.052       0.112\n",
            "C(year_week)[T.201126]     0.1009      0.044      2.297      0.022       0.015       0.187\n",
            "C(year_week)[T.201127]     0.1534      0.048      3.205      0.001       0.060       0.247\n",
            "C(year_week)[T.201128]     0.2036      0.048      4.219      0.000       0.109       0.298\n",
            "C(year_week)[T.201129]     0.2143      0.042      5.061      0.000       0.131       0.297\n",
            "C(year_week)[T.201130]     0.2124      0.042      5.019      0.000       0.129       0.295\n",
            "C(year_week)[T.201131]     0.2377      0.042      5.598      0.000       0.154       0.321\n",
            "C(year_week)[T.201132]     0.2154      0.044      4.948      0.000       0.130       0.301\n",
            "C(year_week)[T.201133]     0.1986      0.044      4.558      0.000       0.113       0.284\n",
            "treatment                  0.0630      0.053      1.183      0.237      -0.041       0.167\n",
            "commute120                 0.0415      0.052      0.795      0.427      -0.061       0.144\n",
            "treatment:commute120       0.0528      0.067      0.789      0.430      -0.078       0.184\n",
            "==============================================================================\n",
            "Omnibus:                     1634.124   Durbin-Watson:                   2.057\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            11077.737\n",
            "Skew:                          -1.967   Prob(JB):                         0.00\n",
            "Kurtosis:                      10.484   Cond. No.                         43.4\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors are robust to cluster correlation (cluster)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue4pLDtCnIF2"
      },
      "source": [
        "'# Give the verbal answer here:\n",
        "\n",
        "- with the inclusion of the interaction term the coefficient of the treatment dummy drops to 0.0630, i.e. 6.3 % higher performance, but is statistically insignificant (p=0.237). The interaction term is statistically insignificant but amounts with 0.0528 to almost the size of the treatment dummy alone. This means that workers that have a commuting distance of more than 120 min. in total show an additional performance increase of 5.28% on average, thus indicating that the effect of working from home is particularly pronounced for this group.\n",
        "- a potential reason for this increased effect might be that these employees now use the saved commuting time to be productive within their job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN8TePjznIF2"
      },
      "source": [
        "__c)__ As explained above, the researchers first explored which employees would be willing to work from home and then randomly selected a subgroup amongst these employees who would take part in the treatment. Explain why this is an essential step to estimate the causal effect of the treatment. \n",
        "\n",
        "<div style=\"text-align: right\"> <b>5 points</b> </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeVBZcoenIF2"
      },
      "source": [
        "'# Give the verbal answer here:\n",
        "- if the researchers would not have done that there would be a high risk of selection bias which would bias the estimated treatment effects.\n",
        "- if for example especially those employees that think that they would be more productive at home select into the treatment, the effect would be overestimated.\n",
        "- if, however, especially lazy employees that think that they would be less monitored at home select into the treatment, this might result in underestimating the treatment effect.\n",
        "- using this specific approach ensures that the two groups are comparable with respect to unobservable measures and then treatment is randomly assigned within this homogenous group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iCMC_jpnIF2"
      },
      "source": [
        "__d)__ Assume now working from home would not have been randomly assigned, i.e., employees could decide individually whether they want to take part in working from home or not. Which alternative method could help to estimate the causal effect of the management practice in this case. Please also explain verbally which assumption(s) you would have to impose to give a causal \n",
        "interpretation of the results.\n",
        "\n",
        "<div style=\"text-align: right\"> <b>5 points</b> </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfsCt_JdnIF2"
      },
      "source": [
        "'# Give the verbal answer here:\n",
        "- Use panel data which observes individuals over several months before and after the opportunity to work from home. The effects could then be estimated using fixed effects regressions which only uses variation within a person to control for selection. The key underlying assumption is that there are *common trends* in performance, i.e. those who decided to work from home would have similar time trends in their performance if they instead had to work in the office as those who voluntarily stayed in the office. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N92ikWDknIF2"
      },
      "source": [
        "## Assignment 2 (30 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJhba1JqnIF2"
      },
      "source": [
        "_Your general task in this assignment is to use employee features listed below to predict employees' performance. In the first part of the exercise, you will perform data cleaning. In the second part, you are tasked with (i) finding the optimal Random Forest regressor to predict performance (i.e., model selection) and (ii) estimating the general performance of the selected model (i.e. model assessment)._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfuld063nIF2"
      },
      "source": [
        "The dataset data_task2.csv contains the following variables from a pre-experimental period on a subset of the employees:\n",
        "\n",
        "- *personid*: individual employee identifier\n",
        "- *age*: age in years\n",
        "- *tenure*: tenure in months\n",
        "- *wage*: gross wage\n",
        "- *children*: children dummy, indicating whether the employee has children\n",
        "- *bedroom*: bedroom dummy, indicating whether the employee has a bedroom\n",
        "- *commute*: commuting time in minutes\n",
        "- *men*: gender dummy, indicating whether the employee is male\n",
        "- *married*: marriage dummy, indicating whether the employee is married\n",
        "- *volunteer*: volunteering dummy, indicating whether the employee volunteered for working from home in the experiment\n",
        "- *high_educ*: education dummy, indicating whether the employee has a higher education\n",
        "- *z_performance*: performance measure, which indicates the standardized performance of the employee (i.e. subtracted by the mean and divided by the standard deviation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAi0YVkInIF2"
      },
      "source": [
        "**a)** Using *data_task2.csv*, remove the 'wage' and 'personid' columns from the dataframe and remove any row that contains missing values (i.e. 'NaN's).\n",
        "<div style=\"text-align: right\"> <b>2 points</b> </div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su2o89UInIF2"
      },
      "source": [
        "# Insert your code here:\n",
        "df2 = df2.drop(columns=['personid','wage'])\n",
        "df2 = df2.dropna()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmtkVKNSnIF2"
      },
      "source": [
        "**b)** Split the data into a training set containing 75% of the observations and a test set containing 25% of the observations. Use 181 as the random state to allow for reproducibility.\n",
        "<div style=\"text-align: right\"> <b>2 points</b> </div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Hk-9imnIF3"
      },
      "source": [
        "# Insert your code here:\n",
        "y = df2['z_performance']\n",
        "\n",
        "X = df2.drop(columns='z_performance')\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=181)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP7aS5GPnIF3"
      },
      "source": [
        "_In the following, you wish to apply the Cross Validation (CV) technique on the training set to find the optimal Random Forest regressor that can predict performance based on all the other features._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3en6W3LnIF3"
      },
      "source": [
        "__c)__ Before you perform the model selection, please state and justify your choice of (i) number of folds in the Cross Validation (CV), (ii) hyperparameters, and (iii) parameter grid (i.e. the dictionary containing the hyperparameter candidates).\n",
        "<div style=\"text-align: right\"> <b>6 points</b> </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxl9isnynIF3"
      },
      "source": [
        "'# Give the verbal answer here:\n",
        "- (i) When choosing the number of folds in the CV procedure, we are facing a bias-variance trade-off. If we pick a low number of folds, we will tend to get biased estimate. If we choose a high number of folds, our estimates will have high variance. The optimal number of folds depends on the model's learning curve, which is unknown. A often used compromise is to choose k=5 or k=10. \n",
        "\n",
        "- (ii) The most important hyper parameters for the random forest regressor are (a) the number of trees, (b) the number of features available to each tree when making a split, (c) the maximum depth of each tree in the ensemble, (d) the minimum required observations per split and (e) the minimum required observations per leaf. \n",
        "\n",
        "- (iii) We vary the number of features available to be between 1-9, the maximum depth to be between 1 and 100, the minimum required observations per split and leaf to be between 1 and 100 in order to decorrelate the trees in our ensemble. We vary the number of trees to be between 500-1000 trees to make sure that we have a sufficient amount of them. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMNPW03tnIF3"
      },
      "source": [
        "__d)__ Based on your answer in c), perform the model selection and print the optimal Random Forest regressor.\n",
        "<div style=\"text-align: right\"> <b>8 points</b> </div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZQoYWYanIF3",
        "outputId": "18be65e6-07cd-4f3b-ce33-27d9196de906"
      },
      "source": [
        "# Insert your code here:\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_grid = {'max_features': np.arange(1, 9),\n",
        "              'max_depth': np.arange(1,100),\n",
        "              'min_samples_split': np.arange(1, 100),\n",
        "              'min_samples_leaf': np.arange(1, 100),\n",
        "             'n_estimators': np.arange(500, 1001, 100)}\n",
        "\n",
        "rf_cv = RandomizedSearchCV(RandomForestRegressor(), param_grid, cv=5, n_iter=10,\n",
        "                           n_jobs=-1, verbose=-1).fit(X_train, y_train)\n",
        "\n",
        "rf_cv.best_estimator_"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_depth=22, max_features=3, min_samples_leaf=22,\n",
              "                      min_samples_split=64, n_estimators=600)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqLOw2PevC93"
      },
      "source": [
        "**IMPORTANT NOTE: If you face a task similar to the one above where you are required to define and use an exhaustive parameter grid, please make use of RandomizedSearchCV and set n_iter=10 when you perform the cross validation unless it is explicitly stated that you should not. If one would use GridSearchCV for the parameter grid above, you would not be able to execute the code in time.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM1PSE9ynIF3"
      },
      "source": [
        "**e)** Print out the feature importance of all the features of the optimal Random Forest regressor you found in d). Which three features are most predictive of performance? Provide a potential reason for this.\n",
        "<div style=\"text-align: right\"> <b>8 points</b> </div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "WG4TgPOvnIF3",
        "outputId": "058358d3-962a-418d-f7b7-4ff3c74d93d1"
      },
      "source": [
        "# Insert your code here:\n",
        "pd.Series(rf_cv.best_estimator_.feature_importances_*100, index=X_train.columns).plot(kind='barh');"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a173qb2KnIF3"
      },
      "source": [
        "'# Give the verbal answer here:\n",
        "- Responses may vary here dependent on the hyperparameters chosen by the students and the randomness of the procedure, but usually it we get tenure, age and commute as the most important features. Tenure and age are of course highly correlated, so the reasons for this may be the same: More experience leads to higher performance. Commute is more difficult. Perhaps employees living further away are, on average, more engaged in working at the specific company (selection effect)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc-DEk2WnIF3"
      },
      "source": [
        "**f)** Now get an unbiased estimate of the squared error of the optimal Random Forest regressor you found in d). Explain why this estimate is better than calculating the mean squared error on the training set.\n",
        "<div style=\"text-align: right\"> <b>4 points</b> </div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6qw_5AJnIF3",
        "outputId": "06b97b6c-bd44-4ac0-db6c-74eac7a4a01f"
      },
      "source": [
        "# Insert your code here:\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "y_pred = rf_cv.predict(X_test)\n",
        "\n",
        "print('test MSE: ', mean_squared_error(y_test, y_pred))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test MSE:  0.43423175142566534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdw3rRpKnIF4"
      },
      "source": [
        "'# Give the verbal answer here:\n",
        "- If we use the training data to get an estimate of the regressor's general performance, we are using data that the model already \"knows\" and was fitted on. Thus, this will generally lead to a too optimistic estimate. Therefore, it is better to use the test data which the model has not \"seen\" to get the estimate."
      ]
    }
  ]
}